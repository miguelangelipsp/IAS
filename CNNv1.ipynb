{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c909d8cc-4024-48a2-8a08-7c3a507ba107",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 18:06:38.821577: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-17 18:06:39.740735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 18:06:43.364150: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: UNKNOWN ERROR (34)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e24adb-3a42-4829-8272-03c183976bd6",
   "metadata": {},
   "source": [
    "# 1. Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeb24ff-072f-400e-a830-90195f9c6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "326132b0-031a-4f5e-9987-f0c8950b5a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 18:56:57.541736: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-17 18:56:57.587469: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#modelos\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92b1ef3-1946-4f10-a272-7827d1887e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar dataset con los datos etiquetados\n",
    "annotations = pd.read_csv('workspace/annotations/_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d750f5a-d6c0-4064-97f1-fc6ab8930e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear un codificador de clases\n",
    "le = LabelEncoder()\n",
    "annotations['class'] = le.fit_transform(annotations['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f607de19-616e-461e-993f-e78718e9ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar imagenes, cajas etiquetadas y etiqueta de la caja\n",
    "def load_image_and_boxes(annotations, image_dir):\n",
    "    images = []\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in annotations.iterrows():\n",
    "        image_path = os.path.join(image_dir, row['filename'])\n",
    "        image = cv2.imread(image_path)\n",
    "        height, width, _ = image.shape\n",
    "        \n",
    "        # Normalizar bounding boxes\n",
    "        xmin = row['xmin'] / width\n",
    "        ymin = row['ymin'] / height\n",
    "        xmax = row['xmax'] / width\n",
    "        ymax = row['ymax'] / height\n",
    "        \n",
    "        images.append(image)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "        labels.append(row['class'])\n",
    "    \n",
    "    return np.array(images), np.array(boxes), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "000eac61-73b4-49f6-9cae-66b6b4cbc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'workspace/images/train/'\n",
    "images, boxes, labels = load_image_and_boxes(annotations, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068f8ef-5627-4eef-a178-5feaed128814",
   "metadata": {},
   "source": [
    "# 2. Crear el Modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1fb292-ff89-4ba3-bfdb-fcfd475b0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#construir modelo cnn\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    input_image = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Extracción de características (Convoluciones)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu')(input_image)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    #predicción del Bounding Box (4 valores: xmin, ymin, xmax, ymax)\n",
    "    box_output = layers.Dense(4, activation='sigmoid', name='box_output')(x)\n",
    "    \n",
    "    #predicción de la clase del objeto\n",
    "    class_output = layers.Dense(num_classes, activation='softmax', name='class_output')(x)\n",
    "    \n",
    "    model = models.Model(inputs=input_image, outputs=[box_output, class_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a100692f-d01e-47b1-b449-95fe1752ec46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-17 18:57:23.591602: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:282] failed call to cuInit: UNKNOWN ERROR (34)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1080</span>,      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1080</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1078</span>,      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1078</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">539</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">539</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">537</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">537</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">268</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">268</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">266</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">266</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">133</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">133</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2264192</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ box_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">9,056,772</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_output        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">4,528,386</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1080\u001b[0m,      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1080\u001b[0m, \u001b[38;5;34m3\u001b[0m)          │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1078\u001b[0m,      │        \u001b[38;5;34m896\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m1078\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m539\u001b[0m, \u001b[38;5;34m539\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m537\u001b[0m, \u001b[38;5;34m537\u001b[0m,  │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m268\u001b[0m, \u001b[38;5;34m268\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m266\u001b[0m, \u001b[38;5;34m266\u001b[0m,  │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m133\u001b[0m, \u001b[38;5;34m133\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2264192\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ box_output (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │  \u001b[38;5;34m9,056,772\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ class_output        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │  \u001b[38;5;34m4,528,386\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,678,406</span> (52.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,678,406\u001b[0m (52.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,678,406</span> (52.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,678,406\u001b[0m (52.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# definir modelo\n",
    "input_shape = (1080, 1080, 3)  # Tamaño de las imágenes (ajusta según sea necesario)\n",
    "num_classes = len(le.classes_)\n",
    "model = build_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', \n",
    "              loss={'box_output': 'mean_squared_error', 'class_output': 'sparse_categorical_crossentropy'}, \n",
    "              metrics={'class_output': 'accuracy'})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c87fa9-3cf0-445d-981d-99818656252b",
   "metadata": {},
   "source": [
    "# 3. Preprocesamiento y redimensionamiento de Imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad796d19-56e5-4f4b-9e3f-4ca72a6ac5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocesar imagenes para asignar a la red\n",
    "def preprocess_images(images, target_size):\n",
    "    resized_images = []\n",
    "    for image in images:\n",
    "        resized_image = cv2.resize(image, target_size)\n",
    "        resized_image = resized_image / 255.0  #normalizar los valores de los píxeles\n",
    "        resized_images.append(resized_image)\n",
    "    return np.array(resized_images)\n",
    "\n",
    "target_size = (1080, 1080)  #ajustar al tamaño de la entrada de la red\n",
    "images_resized = preprocess_images(images, target_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391d489b-ce90-4e0c-9063-4277253375e6",
   "metadata": {},
   "source": [
    "# 4. Entrenamiento del modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "759f87d9-ef0b-474f-a04c-849af2f4840f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 2s/step - class_output_accuracy: 0.6482 - loss: 5.9786 - val_class_output_accuracy: 0.9150 - val_loss: 0.4198\n",
      "Epoch 2/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - class_output_accuracy: 0.8004 - loss: 0.5348 - val_class_output_accuracy: 0.9150 - val_loss: 0.3743\n",
      "Epoch 3/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - class_output_accuracy: 0.8105 - loss: 0.5108 - val_class_output_accuracy: 0.9150 - val_loss: 0.4232\n",
      "Epoch 4/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - class_output_accuracy: 0.8006 - loss: 0.5369 - val_class_output_accuracy: 0.9150 - val_loss: 0.4106\n",
      "Epoch 5/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - class_output_accuracy: 0.7960 - loss: 0.5329 - val_class_output_accuracy: 0.9150 - val_loss: 0.3675\n",
      "Epoch 6/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - class_output_accuracy: 0.7881 - loss: 0.5345 - val_class_output_accuracy: 0.9150 - val_loss: 0.3596\n",
      "Epoch 7/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - class_output_accuracy: 0.8028 - loss: 0.5206 - val_class_output_accuracy: 0.9150 - val_loss: 0.3482\n",
      "Epoch 8/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - class_output_accuracy: 0.7790 - loss: 0.5879 - val_class_output_accuracy: 0.9150 - val_loss: 0.3603\n",
      "Epoch 9/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - class_output_accuracy: 0.8007 - loss: 0.5266 - val_class_output_accuracy: 0.9150 - val_loss: 0.3692\n",
      "Epoch 10/10\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 2s/step - class_output_accuracy: 0.7874 - loss: 0.5335 - val_class_output_accuracy: 0.9150 - val_loss: 0.3620\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(images_resized, {'box_output': boxes, 'class_output': labels}, \n",
    "                    epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca057006-93c3-4f1f-8956-d0a58076b45e",
   "metadata": {},
   "source": [
    "# 5. Evaluación de Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8842d3-8b86-40d7-847e-2f6e87368d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en una nueva imagen\n",
    "new_image = cv2.imread('path_to_new_image.jpg')\n",
    "new_image_resized = preprocess_images([new_image], target_size)\n",
    "\n",
    "predictions = model.predict(new_image_resized)\n",
    "predicted_box = predictions[0][0]  # Coordenadas del bounding box\n",
    "predicted_class = np.argmax(predictions[1][0])  # Clase predicha\n",
    "\n",
    "print(f\"Bounding Box: {predicted_box}\")\n",
    "print(f\"Clase Predicha: {le.inverse_transform([predicted_class])[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab7ebb-7935-489b-aeca-a1279fdc70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizar el resultado\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))\n",
    "xmin, ymin, xmax, ymax = predicted_box\n",
    "height, width, _ = new_image.shape\n",
    "plt.gca().add_patch(plt.Rectangle((xmin * width, ymin * height), (xmax - xmin) * width, (ymax - ymin) * height, \n",
    "                                  edgecolor='r', facecolor='none', lw=2))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
